{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the files that come out of preprocess_redi.py\n",
    "files = ['NEG.filtered_edits.csv', 'cLIDAR.filtered_edits.csv', 'eLIDAR.filtered_edits.csv', 'gLIDAR.filtered_edits.csv', 'AD2.filtered_edits.csv']\n",
    "#files = ['NG4AVP.filtered_edits.csv','noAVP.filtered_edits.csv','AVP.filtered_edits.csv']\n",
    "num_files=len(files)\n",
    "base_dir='./data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of files: 5\n",
      "./data/NEG.filtered_edits.csv\n",
      "./data/cLIDAR.filtered_edits.csv\n",
      "./data/eLIDAR.filtered_edits.csv\n",
      "./data/gLIDAR.filtered_edits.csv\n",
      "./data/AD2.filtered_edits.csv\n",
      "First step passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import statsmodels.stats.multitest as mt\n",
    "\n",
    "edit_map = {}\n",
    "sample = 0\n",
    "conds=1 #hardcoded # could be int(num_files/3) if using triplicates,etc\n",
    "\n",
    "print(\"# of files:\", num_files)\n",
    "\n",
    "for file in files:\n",
    "    file = base_dir+file\n",
    "    print(file)\n",
    "    df = pd.read_csv(file, sep=\",\")\n",
    "    for index, row in df.iterrows():\n",
    "        pos = row['Position']\n",
    "        reg = row['Region']\n",
    "\n",
    "        bases = eval(row['BaseCount[A,C,G,T]'])\n",
    "        sum_freq=sum(bases)\n",
    "\n",
    "        if not reg in edit_map:\n",
    "            edit_map[reg]={}\n",
    "        if not pos in edit_map[reg]:\n",
    "            edit_map[reg][pos]= { 'Reference': row['Reference'], 'Frequency': [0]*num_files, 'FisherM': [[0,0]]*num_files }\n",
    "\n",
    "        # if not a minimum of 20 reads then dont consider it\n",
    "        if sum_freq<20 or (row['Reference'] == 'A' and bases[2]<1) or (row['Reference'] == 'T' and bases[1]<1):\n",
    "            if reg in edit_map and pos in edit_map[reg]:\n",
    "                edit_map[reg][pos]['Frequency'][sample]=None\n",
    "            continue\n",
    "        \n",
    "        if row['Reference'] == 'A':\n",
    "            edit_map[reg][pos]['Frequency'][sample]=bases[2]/(bases[0]+bases[2]) #row['Frequency']\n",
    "            edit_map[reg][pos]['FisherM'][sample]=[sum_freq-bases[2], bases[2]] # 2 corresponds to position G\n",
    "        elif row['Reference'] == 'T':\n",
    "            edit_map[reg][pos]['Frequency'][sample]=bases[1]/(bases[3]+bases[1]) #row['Frequency']\n",
    "            edit_map[reg][pos]['FisherM'][sample]=[sum_freq-bases[1], bases[1]] # 1 = position for C\n",
    "\n",
    "    sample+=1\n",
    "    del df\n",
    "\n",
    "print('First step passed\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3297977\n",
      "3297977\n"
     ]
    }
   ],
   "source": [
    "means = [None]*num_files\n",
    "pvaluesx=[]\n",
    "pvaluesy=[]\n",
    "pvals=[]\n",
    "pvals_all=[]\n",
    "gene=[]\n",
    "tables =[]\n",
    "comparison = 0\n",
    "comp_2 = 4\n",
    "high_edit=0\n",
    "total_pos=0\n",
    "e=0.00000001\n",
    "\n",
    "for c in range(len(means)):\n",
    "    means[c]=[]\n",
    "\n",
    "for region, positions in edit_map.items():\n",
    "    for position, sitedata in positions.items():\n",
    "        frequencies = sitedata['Frequency']\n",
    "\n",
    "        if region=='XZ054' and position==3740:\n",
    "            print(region, position, frequencies[comparison],frequencies[comp_2], frequencies[0]>0)\n",
    "\n",
    "        # Based on Katrekar et al (https://doi.org/10.1038/s41592-019-0323-0) protocol. \n",
    "        # Only look at sites shared by all conditions\n",
    "        # Also based on Katrekar et al. If all conditions have the site and at least one is >0\n",
    "        if not None in frequencies:\n",
    "            total_pos+=1\n",
    "            \n",
    "            for c in range(len(means)):\n",
    "                means[c].append(frequencies[conds*c])\n",
    "\n",
    "            table = np.array([sitedata['FisherM'][comparison], sitedata['FisherM'][comp_2]])+e \n",
    "    \n",
    "            if min(table[0])>5 and min(table[1])>5:\n",
    "                fisher = stats.chi2_contingency(table)\n",
    "            else:\n",
    "                fisher = stats.fisher_exact(table)\n",
    "            \n",
    "            try:\n",
    "                pvals_all.append(fisher.pvalue)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "rejected, corrected = mt.multipletests(pvals_all, alpha=0.01, method='fdr_bh')[:2]\n",
    "\n",
    "print(total_pos)\n",
    "print(len(pvals_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4643\n"
     ]
    }
   ],
   "source": [
    "rejected=np.array(rejected)\n",
    "print(len(rejected[rejected]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistically significant changes: 4641\n"
     ]
    }
   ],
   "source": [
    "pvaluesx=[]\n",
    "pvaluesy=[]\n",
    "for i in range(len(means[0])):\n",
    "    if ((means[comp_2][i]/(means[comparison][i]+e)) > 1.1 or (means[comparison][i]/(means[comp_2][i]+e)) > 1.1) and rejected[i]:\n",
    "        pvaluesx.append(means[comparison][i])\n",
    "        pvaluesy.append(means[comp_2][i])\n",
    "\n",
    "print('Statistically significant changes:', len(pvaluesx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib as mpl\n",
    "\n",
    "# modify existing Reds colormap with a linearly fading alpha\n",
    "red = plt.cm.gist_heat  # original colormap\n",
    "fading_red = red(np.arange(red.N)) # extract colors\n",
    "fading_red = fading_red[::-1]\n",
    "fading_red[:, -1] = np.linspace(0.1, 0.9, red.N) # modify alpha\n",
    "fading_red = ListedColormap(fading_red) # convert to colormap\n",
    "\n",
    "plt.hist2d(means[comparison], means[comp_2], bins=(75,75), norm=mpl.colors.LogNorm(vmax=1000000), cmap=mpl.cm.binary)\n",
    "if len(pvaluesx)>0:\n",
    "    plt.hist2d(pvaluesx, pvaluesy, bins=(75,75), cmap=fading_red, norm=mpl.colors.LogNorm(vmin=1, vmax=100), range=[[0, 1], [0, 1]])\n",
    "plt.xlim(0.0, 1)\n",
    "plt.ylim(0.0, 1)\n",
    "if 'XZ054' in edit_map:\n",
    "    x_sensor = edit_map['XZ054'][3740]['Frequency'][comparison]\n",
    "    y_sensor = edit_map['XZ054'][3740]['Frequency'][comp_2]\n",
    "    plt.plot(x_sensor, y_sensor, marker=4, color='#07f0ff', markersize=6)\n",
    "plt.colorbar()\n",
    "\n",
    "sample_names=['NG-noAVP','NG-AVP', 'noAVP-AVP']\n",
    "\n",
    "#plt.savefig(base_dir+'1114_'+sample_names[comp_2+comparison-1]+'.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
